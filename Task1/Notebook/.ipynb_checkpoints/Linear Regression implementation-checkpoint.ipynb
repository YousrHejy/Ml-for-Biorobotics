{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eed5dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Some helpful function \n",
    "# Change the categorical data to numerical data\n",
    "def Encoding(data):\n",
    "    # create the encoder variable\n",
    "    le_encoder = LabelEncoder()\n",
    "    # Extract the categoral data\n",
    "    cat_df = df.select_dtypes(include=['object'])\n",
    "    # Encode the categorecal data\n",
    "    for i in cat_df:\n",
    "        df[i] = le_encoder.fit_transform(df[i])\n",
    "    return df\n",
    "\n",
    "# Function for analusis of data\n",
    "def data_analysis(data):\n",
    "    # The shape of the data\n",
    "    print(\"The shape of the data set:\")\n",
    "    print(f\"The data set consists of {data.shape[0]} rows and {data.shape[1]} columns.\")\n",
    "    \n",
    "    print('\\n***********************************************')\n",
    "    # Missing Values Check\n",
    "    print(\"The existence of missing values in each column:\")\n",
    "    print(data.isnull().any())\n",
    "    \n",
    "    print('\\n***********************************************')\n",
    "    # Info of the data\n",
    "    print(\"General information about the data:\")\n",
    "    print(data.info())\n",
    "    \n",
    "    print('\\n***********************************************')\n",
    "    # Number of unique values in each column\n",
    "    print(\"The number of unique values in each column:\")\n",
    "    print(data.nunique())\n",
    "    \n",
    "    print('\\n***********************************************')\n",
    "    # Number of unique values in each column\n",
    "    print(\"The number of duplicates in df:\", data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a90a14b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'insurance.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14388\\71300652.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"insurance.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'insurance.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73976df",
   "metadata": {},
   "source": [
    "# Preprocessing & Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f2db9",
   "metadata": {},
   "source": [
    "### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b0b73",
   "metadata": {},
   "source": [
    "### Encode the categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae64979",
   "metadata": {},
   "source": [
    "##### for trianing a linear regression model, we need all the input data to be numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Encoding(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393cae2",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f731c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_sc = sc.fit_transform(x)\n",
    "x_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1690b6",
   "metadata": {},
   "source": [
    "# Splitting the data into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7394d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data before scaling\n",
    "X_train, X_test, y_train, y_test = train_test_split( x, y, test_size = 0.3,random_state=42)\n",
    "\n",
    "# splitting the data after scaling\n",
    "X_train_sc, X_test_sc, y_train, y_test = train_test_split( x_sc, y, test_size = 0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ea2e3b",
   "metadata": {},
   "source": [
    "# Modeling using Sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23cb071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# create object of LR class in sklearn\n",
    "lr = LinearRegression()\n",
    "# train the model using train data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# get the predicted target values\n",
    "y_pred = lr.predict(X_test)\n",
    "# find the godness of fit\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "# get the mean square error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# get the root mean square error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "###################### with scaling ###################################\n",
    "# create object of LR class in sklearn\n",
    "lr_sc = LinearRegression()\n",
    "# train the model using train data\n",
    "lr_sc.fit(X_train_sc, y_train)\n",
    "\n",
    "# get the predicted target values\n",
    "y_pred_sc = lr_sc.predict(X_test_sc)\n",
    "# find the godness of fit\n",
    "r2_sc = r2_score(y_test, y_pred_sc)\n",
    "# get the mean square error\n",
    "mse_sc = mean_squared_error(y_test, y_pred_sc)\n",
    "# get the root mean square error\n",
    "rmse_sc = np.sqrt(mse_sc)\n",
    "\n",
    "print(\"The R2 score:\", r2)\n",
    "print(\"the mean square error:\", mse,)\n",
    "print(\"the root mean square error:\", rmse)\n",
    "print(\"#############################################\")\n",
    "print(\"The R2 score with scaling:\", r2_sc)\n",
    "print(\"the mean square error with scaling:\", mse_sc)\n",
    "print(\"the root mean square error with scaling:\", rmse_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c756752",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"Actual\": y_pred, \"Predicted\": y_test})\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a233479d",
   "metadata": {},
   "source": [
    "#### Plotting the actual and predicted value of SKlearn LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the actual values\n",
    "ax.plot(y_test, label='Actual')\n",
    "\n",
    "# Plot the predicted values\n",
    "ax.plot(y_pred, label='Predicted')\n",
    "\n",
    "# Set the labels and title\n",
    "ax.set_xlabel('Index')\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('Actual vs Predicted')\n",
    "\n",
    "# Show the legend\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee8cf5",
   "metadata": {},
   "source": [
    "# Scratch Multiple LR Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a61266",
   "metadata": {},
   "source": [
    "The prediction of the Miltiple LR model: \n",
    "    $$\n",
    "    f_{wb}(x^{(i)}) =  \\sum_{k=1}^{k=m}w_kx^{(i)} + b \n",
    "    $$\n",
    "\n",
    "The gradient descent algorithm is:\n",
    "$$\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & \\phantom {0000} b := b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b} \\newline       \\; & \\phantom {0000} w_k := w_k -  \\alpha \\frac{\\partial J(w,b)}{\\partial w_k} \\tag{1}  \\; & \n",
    "\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "where, parameters $w, b$ are both updated simultaniously and where for **LINEAR REGRESSION**\n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial b}  = \\frac{1}{n} \\sum\\limits_{i = 0}^{N} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial w_k}  = \\frac{1}{n} \\sum\\limits_{i = 0}^{N} (f_{w,b}(x^{(i)}) -y^{(i)})x^{(i)}_k \\tag{3}\n",
    "$$\n",
    "    \n",
    "*  $f_{w,b}(x^{(i)})$ is the model's prediction, while $y^{(i)}$, is the target value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca226d",
   "metadata": {},
   "source": [
    "The total mean square error (difference between actual & predicted):\n",
    "$$\n",
    "MSE = \\frac{1}{n} (yhat  - ytrue)^2\n",
    "$$\n",
    "\n",
    "The R2 Score (goodness of fit):\n",
    "$$\n",
    "R2 = 1 - \\frac{SSR}{SST} = 1 - \\frac{\\sum\\limits_{i = 0}^{N}(yhat  - ytrue)^2}{\\sum\\limits_{i = 0}^{N}(ytrue  - ybar)^2} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5f177",
   "metadata": {},
   "source": [
    "#### Intuation of linear regression class:\n",
    "1.\tInitialize the weights and Bias with zero\n",
    "2.\tPredict the target from a given data point through:\n",
    " $y = wx + b$\n",
    "3.\t Calculate the error using mean square error\n",
    "4.\tUse gradient descent to find new weights and Bias with min error\n",
    "5.\tRepeat for n times until the derivative = 0, which corresponds to reaching the global minima of the function, but it is optional according to the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0fe749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionScratch:\n",
    "    # should initialize the model with number of learning iterations\n",
    "    # also define the step during updating the Wieghts and Bais\n",
    "    def __init__(self, learning_rate=0.01, iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.cost_history = []\n",
    "\n",
    "    def cost_function(self, x, y):\n",
    "        cost = np.sum((((x.dot(self.weight) + self.bais) - y) ** 2) / (2 * len(y)))\n",
    "        return cost\n",
    "\n",
    "    def GradientDescent(self, x, y):\n",
    "        # get the number of samples needed in equation of derivatives \n",
    "        self.no_samples, self.no_features = x.shape\n",
    "        # initialize the weight matrix with zeros at first\n",
    "        self.weight = np.zeros(x.shape[1])\n",
    "        # initialize the bais with zero at first\n",
    "        self.bais = 0\n",
    "\n",
    "        for itteration in range(self.iterations):\n",
    "            # get the predicted point\n",
    "            z = np.dot(x, self.weight) + self.bais\n",
    "            # find the difference between predicted point and actual\n",
    "            loss = z - y\n",
    "            # find the derivative of wieght and bais according to euations\n",
    "            # took the transpose of X from (columns x rows) to (rows x columns) \n",
    "            # as the dimension of W matrix = (rows x 1)\n",
    "            # this will produce matrix = (columns x 1)\n",
    "            dw = np.dot(x.T, loss) / self.no_samples\n",
    "            db = np.sum(loss) / self.no_samples\n",
    "            # update the weights and bais to decrease the error\n",
    "            self.weight -= self.learning_rate * dw\n",
    "            self.bais -= self.learning_rate * db\n",
    "            \n",
    "            # add the cost function of each iteration\n",
    "            cost = self.cost_function(x, y)\n",
    "            self.cost_history.append(cost)\n",
    "            # print the cost after each cycle itteration\n",
    "            if (itteration % (self.iterations / 10) == 0):\n",
    "                print(\"Cost is:\", cost)\n",
    "\n",
    "        return self.weight, self.bais, self.cost_history\n",
    "    \n",
    "    # predict the values of target\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.weight) + self.bais\n",
    "    \n",
    "    def r2score(self, y_pred, y):\n",
    "        y_mean = y.mean()\n",
    "        ssr = np.sum((y_pred - y) ** 2)\n",
    "        sst = np.sum((y-y_mean) ** 2)\n",
    "        r2 = 1 - (ssr / sst)\n",
    "#         r2 = round(r2, 2)\n",
    "        return r2\n",
    "    \n",
    "    def mse(self, y_pred, y):\n",
    "        error = (1 / len(y)) * (np.sum((y_pred - y) ** 2))\n",
    "#         error = round(error, 2)\n",
    "        return error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39ccd66",
   "metadata": {},
   "source": [
    "### At small learning rate \"0.001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8488eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scratch = LinearRegressionScratch(0.001, 1500)\n",
    "w, b, c= lr_scratch.GradientDescent(X_train_sc, y_train)\n",
    "\n",
    "#Plotting the cost function\n",
    "plt.title(\"Cost Function during Each Itteration\")\n",
    "plt.plot(c)\n",
    "plt.show()\n",
    "\n",
    "# Prediction of new values\n",
    "y_pred_scratch = lr_scratch.predict(X_test_sc)\n",
    "r2_scratch = lr_scratch.r2score(y_pred_scratch, y_test)\n",
    "mse_scratch = lr_scratch.mse(y_pred_scratch, y_test)\n",
    "\n",
    "print(\"#######################################################\")\n",
    "print(\"The Evaluation:\")\n",
    "print(\"The R2 score:\", r2_scratch)\n",
    "print(\"the mean square error:\", mse_scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6650955",
   "metadata": {},
   "source": [
    "### At large learning rate \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scratch = LinearRegressionScratch(2, 100)\n",
    "w, b, c= lr_scratch.GradientDescent(X_train_sc, y_train)\n",
    "\n",
    "#Plotting the cost function\n",
    "plt.title(\"Cost Function during Each Itteration\")\n",
    "plt.plot(c)\n",
    "plt.show()\n",
    "\n",
    "# Prediction of new values\n",
    "y_pred_scratch = lr_scratch.predict(X_test_sc)\n",
    "r2_scratch = lr_scratch.r2score(y_pred_scratch, y_test)\n",
    "mse_scratch = lr_scratch.mse(y_pred_scratch, y_test)\n",
    "\n",
    "print(\"#######################################################\")\n",
    "print(\"The Evaluation:\")\n",
    "print(\"The R2 score:\", r2_scratch)\n",
    "print(\"the mean square error:\", mse_scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a793e39",
   "metadata": {},
   "source": [
    "### At suitable learningrate and itterations \"0.01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scratch = LinearRegressionScratch(0.01, 15000)\n",
    "w, b, c= lr_scratch.GradientDescent(X_train_sc, y_train)\n",
    "\n",
    "#Plotting the cost function\n",
    "plt.title(\"Cost Function during Each Itteration\")\n",
    "plt.plot(c)\n",
    "plt.show()\n",
    "\n",
    "# Prediction of new values\n",
    "y_pred_scratch = lr_scratch.predict(X_test_sc)\n",
    "r2_scratch = lr_scratch.r2score(y_pred_scratch, y_test)\n",
    "mse_scratch = lr_scratch.mse(y_pred_scratch, y_test)\n",
    "\n",
    "print(\"#######################################################\")\n",
    "print(\"The Evaluation:\")\n",
    "print(\"The R2 score:\", r2_scratch)\n",
    "print(\"the mean square error:\", mse_scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506817a8",
   "metadata": {},
   "source": [
    "##### Predicting a random sample from training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8de096",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = X_train_sc[2]\n",
    "y_sample = lr_scratch.predict(x_sample)\n",
    "print(f\"the Actual value: {y_train[2]}, the predicated value: {y_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b99df07",
   "metadata": {},
   "source": [
    "#### Plotting the actual and predicted value of scratch LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the actual values\n",
    "ax.plot(y_test, label='Actual')\n",
    "\n",
    "# Plot the predicted values\n",
    "ax.plot(y_pred_scratch, label='Predicted')\n",
    "\n",
    "# Set the labels and title\n",
    "ax.set_xlabel('Index')\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('Actual vs Predicted')\n",
    "\n",
    "# Show the legend\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8cacb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
